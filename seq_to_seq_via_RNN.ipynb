{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c2d4d57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62b9f5a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_1</th>\n",
       "      <th>f2_1</th>\n",
       "      <th>f3_1</th>\n",
       "      <th>f4_1</th>\n",
       "      <th>f5_1</th>\n",
       "      <th>f6_1</th>\n",
       "      <th>f7_1</th>\n",
       "      <th>f8_1</th>\n",
       "      <th>f9_1</th>\n",
       "      <th>f10_1</th>\n",
       "      <th>f11_1</th>\n",
       "      <th>f12_1</th>\n",
       "      <th>f13_1</th>\n",
       "      <th>f14_1</th>\n",
       "      <th>f15_1</th>\n",
       "      <th>f16_1</th>\n",
       "      <th>f17_1</th>\n",
       "      <th>f18_1</th>\n",
       "      <th>f19_1</th>\n",
       "      <th>f20_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.696794</td>\n",
       "      <td>-0.621645</td>\n",
       "      <td>-2.350322</td>\n",
       "      <td>0.857568</td>\n",
       "      <td>0.183480</td>\n",
       "      <td>0.929362</td>\n",
       "      <td>1.662710</td>\n",
       "      <td>3.002824</td>\n",
       "      <td>-0.952821</td>\n",
       "      <td>0.780778</td>\n",
       "      <td>-2.149981</td>\n",
       "      <td>-0.096125</td>\n",
       "      <td>0.686564</td>\n",
       "      <td>0.932175</td>\n",
       "      <td>1.035598</td>\n",
       "      <td>0.100794</td>\n",
       "      <td>0.472664</td>\n",
       "      <td>0.961984</td>\n",
       "      <td>-1.581007</td>\n",
       "      <td>0.418345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.490176</td>\n",
       "      <td>-1.369651</td>\n",
       "      <td>-6.381362</td>\n",
       "      <td>2.446793</td>\n",
       "      <td>0.648104</td>\n",
       "      <td>5.127069</td>\n",
       "      <td>3.632748</td>\n",
       "      <td>6.645584</td>\n",
       "      <td>-1.694836</td>\n",
       "      <td>1.961207</td>\n",
       "      <td>-5.393690</td>\n",
       "      <td>-1.725572</td>\n",
       "      <td>1.115977</td>\n",
       "      <td>2.599284</td>\n",
       "      <td>1.849126</td>\n",
       "      <td>0.149453</td>\n",
       "      <td>1.651858</td>\n",
       "      <td>2.380088</td>\n",
       "      <td>-2.989520</td>\n",
       "      <td>1.523643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.195791</td>\n",
       "      <td>-1.803062</td>\n",
       "      <td>-8.885239</td>\n",
       "      <td>1.678346</td>\n",
       "      <td>1.484633</td>\n",
       "      <td>7.669556</td>\n",
       "      <td>5.218378</td>\n",
       "      <td>9.897765</td>\n",
       "      <td>-2.370407</td>\n",
       "      <td>2.332558</td>\n",
       "      <td>-7.979431</td>\n",
       "      <td>-2.123378</td>\n",
       "      <td>1.262524</td>\n",
       "      <td>3.922189</td>\n",
       "      <td>2.477547</td>\n",
       "      <td>1.246901</td>\n",
       "      <td>1.795737</td>\n",
       "      <td>2.639566</td>\n",
       "      <td>-4.948484</td>\n",
       "      <td>1.801274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.943051</td>\n",
       "      <td>0.117324</td>\n",
       "      <td>-11.007327</td>\n",
       "      <td>0.045042</td>\n",
       "      <td>2.026570</td>\n",
       "      <td>7.370177</td>\n",
       "      <td>6.339163</td>\n",
       "      <td>11.226333</td>\n",
       "      <td>-2.778230</td>\n",
       "      <td>3.804610</td>\n",
       "      <td>-8.785526</td>\n",
       "      <td>-1.515712</td>\n",
       "      <td>0.418063</td>\n",
       "      <td>2.784484</td>\n",
       "      <td>2.132019</td>\n",
       "      <td>1.920771</td>\n",
       "      <td>1.803917</td>\n",
       "      <td>2.866873</td>\n",
       "      <td>-4.924506</td>\n",
       "      <td>1.716181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.792690</td>\n",
       "      <td>2.802358</td>\n",
       "      <td>-5.212722</td>\n",
       "      <td>-1.270905</td>\n",
       "      <td>0.897933</td>\n",
       "      <td>4.450223</td>\n",
       "      <td>2.796456</td>\n",
       "      <td>7.543190</td>\n",
       "      <td>-1.245164</td>\n",
       "      <td>1.265860</td>\n",
       "      <td>-4.883092</td>\n",
       "      <td>-0.436753</td>\n",
       "      <td>-0.691122</td>\n",
       "      <td>2.223674</td>\n",
       "      <td>-0.473904</td>\n",
       "      <td>0.735597</td>\n",
       "      <td>1.970611</td>\n",
       "      <td>0.547733</td>\n",
       "      <td>-3.001847</td>\n",
       "      <td>0.299120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       f1_1      f2_1       f3_1      f4_1      f5_1      f6_1      f7_1  \\\n",
       "0  1.696794 -0.621645  -2.350322  0.857568  0.183480  0.929362  1.662710   \n",
       "1  4.490176 -1.369651  -6.381362  2.446793  0.648104  5.127069  3.632748   \n",
       "2  6.195791 -1.803062  -8.885239  1.678346  1.484633  7.669556  5.218378   \n",
       "3  5.943051  0.117324 -11.007327  0.045042  2.026570  7.370177  6.339163   \n",
       "4  1.792690  2.802358  -5.212722 -1.270905  0.897933  4.450223  2.796456   \n",
       "\n",
       "        f8_1      f9_1     f10_1     f11_1     f12_1     f13_1     f14_1  \\\n",
       "0   3.002824 -0.952821  0.780778 -2.149981 -0.096125  0.686564  0.932175   \n",
       "1   6.645584 -1.694836  1.961207 -5.393690 -1.725572  1.115977  2.599284   \n",
       "2   9.897765 -2.370407  2.332558 -7.979431 -2.123378  1.262524  3.922189   \n",
       "3  11.226333 -2.778230  3.804610 -8.785526 -1.515712  0.418063  2.784484   \n",
       "4   7.543190 -1.245164  1.265860 -4.883092 -0.436753 -0.691122  2.223674   \n",
       "\n",
       "      f15_1     f16_1     f17_1     f18_1     f19_1     f20_1  \n",
       "0  1.035598  0.100794  0.472664  0.961984 -1.581007  0.418345  \n",
       "1  1.849126  0.149453  1.651858  2.380088 -2.989520  1.523643  \n",
       "2  2.477547  1.246901  1.795737  2.639566 -4.948484  1.801274  \n",
       "3  2.132019  1.920771  1.803917  2.866873 -4.924506  1.716181  \n",
       "4 -0.473904  0.735597  1.970611  0.547733 -3.001847  0.299120  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_EHR1 = pd.read_csv(\"./data_EHR1.csv\")\n",
    "data_EHR1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1ccaa9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 20)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_EHR1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "623b940c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_2</th>\n",
       "      <th>f2_2</th>\n",
       "      <th>f3_2</th>\n",
       "      <th>f4_2</th>\n",
       "      <th>f5_2</th>\n",
       "      <th>f15_2</th>\n",
       "      <th>f14_2</th>\n",
       "      <th>f6_2</th>\n",
       "      <th>f17_2</th>\n",
       "      <th>f9_2</th>\n",
       "      <th>f7_2</th>\n",
       "      <th>f12_2</th>\n",
       "      <th>f20_2</th>\n",
       "      <th>f19_2</th>\n",
       "      <th>f11_2</th>\n",
       "      <th>f18_2</th>\n",
       "      <th>f10_2</th>\n",
       "      <th>f16_2</th>\n",
       "      <th>f8_2</th>\n",
       "      <th>f13_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.002464</td>\n",
       "      <td>-0.054770</td>\n",
       "      <td>-1.607723</td>\n",
       "      <td>0.413153</td>\n",
       "      <td>0.526490</td>\n",
       "      <td>0.808553</td>\n",
       "      <td>0.521133</td>\n",
       "      <td>1.489252</td>\n",
       "      <td>1.093870</td>\n",
       "      <td>-0.143866</td>\n",
       "      <td>1.521181</td>\n",
       "      <td>-1.214374</td>\n",
       "      <td>-0.054487</td>\n",
       "      <td>-0.620618</td>\n",
       "      <td>-0.165420</td>\n",
       "      <td>0.877329</td>\n",
       "      <td>0.684882</td>\n",
       "      <td>-0.041809</td>\n",
       "      <td>2.285389</td>\n",
       "      <td>-0.688339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.208255</td>\n",
       "      <td>-0.430312</td>\n",
       "      <td>3.542310</td>\n",
       "      <td>0.273496</td>\n",
       "      <td>0.523185</td>\n",
       "      <td>1.403259</td>\n",
       "      <td>0.807507</td>\n",
       "      <td>-0.765867</td>\n",
       "      <td>0.872294</td>\n",
       "      <td>0.744647</td>\n",
       "      <td>-0.662414</td>\n",
       "      <td>0.211199</td>\n",
       "      <td>-0.622928</td>\n",
       "      <td>0.033095</td>\n",
       "      <td>1.369378</td>\n",
       "      <td>1.721680</td>\n",
       "      <td>-1.527514</td>\n",
       "      <td>-0.234272</td>\n",
       "      <td>0.200160</td>\n",
       "      <td>-0.147486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.177253</td>\n",
       "      <td>-0.359707</td>\n",
       "      <td>7.928680</td>\n",
       "      <td>0.673136</td>\n",
       "      <td>-0.539660</td>\n",
       "      <td>0.083743</td>\n",
       "      <td>0.467750</td>\n",
       "      <td>-3.756303</td>\n",
       "      <td>-0.516528</td>\n",
       "      <td>1.122243</td>\n",
       "      <td>-4.087978</td>\n",
       "      <td>-0.085167</td>\n",
       "      <td>-1.435108</td>\n",
       "      <td>-0.203887</td>\n",
       "      <td>3.237390</td>\n",
       "      <td>1.130163</td>\n",
       "      <td>-3.310383</td>\n",
       "      <td>-1.228359</td>\n",
       "      <td>-3.529958</td>\n",
       "      <td>0.776517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.293687</td>\n",
       "      <td>-0.708697</td>\n",
       "      <td>6.471826</td>\n",
       "      <td>0.595019</td>\n",
       "      <td>-2.137115</td>\n",
       "      <td>-0.089151</td>\n",
       "      <td>-1.102489</td>\n",
       "      <td>-3.336020</td>\n",
       "      <td>-0.365526</td>\n",
       "      <td>0.826688</td>\n",
       "      <td>-4.684949</td>\n",
       "      <td>-0.328677</td>\n",
       "      <td>-1.541318</td>\n",
       "      <td>-0.260947</td>\n",
       "      <td>2.497054</td>\n",
       "      <td>-0.693162</td>\n",
       "      <td>-2.074722</td>\n",
       "      <td>-1.027206</td>\n",
       "      <td>-3.263632</td>\n",
       "      <td>0.990452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.941395</td>\n",
       "      <td>-1.305723</td>\n",
       "      <td>3.126918</td>\n",
       "      <td>-0.427142</td>\n",
       "      <td>-2.480852</td>\n",
       "      <td>-0.253852</td>\n",
       "      <td>-1.456013</td>\n",
       "      <td>-1.420847</td>\n",
       "      <td>0.261801</td>\n",
       "      <td>0.014554</td>\n",
       "      <td>-1.940401</td>\n",
       "      <td>-0.648343</td>\n",
       "      <td>-1.986704</td>\n",
       "      <td>-0.346978</td>\n",
       "      <td>-0.000081</td>\n",
       "      <td>-1.558701</td>\n",
       "      <td>-0.040872</td>\n",
       "      <td>-0.748870</td>\n",
       "      <td>-0.606107</td>\n",
       "      <td>1.572000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       f1_2      f2_2      f3_2      f4_2      f5_2     f15_2     f14_2  \\\n",
       "0  1.002464 -0.054770 -1.607723  0.413153  0.526490  0.808553  0.521133   \n",
       "1 -0.208255 -0.430312  3.542310  0.273496  0.523185  1.403259  0.807507   \n",
       "2 -3.177253 -0.359707  7.928680  0.673136 -0.539660  0.083743  0.467750   \n",
       "3 -3.293687 -0.708697  6.471826  0.595019 -2.137115 -0.089151 -1.102489   \n",
       "4  0.941395 -1.305723  3.126918 -0.427142 -2.480852 -0.253852 -1.456013   \n",
       "\n",
       "       f6_2     f17_2      f9_2      f7_2     f12_2     f20_2     f19_2  \\\n",
       "0  1.489252  1.093870 -0.143866  1.521181 -1.214374 -0.054487 -0.620618   \n",
       "1 -0.765867  0.872294  0.744647 -0.662414  0.211199 -0.622928  0.033095   \n",
       "2 -3.756303 -0.516528  1.122243 -4.087978 -0.085167 -1.435108 -0.203887   \n",
       "3 -3.336020 -0.365526  0.826688 -4.684949 -0.328677 -1.541318 -0.260947   \n",
       "4 -1.420847  0.261801  0.014554 -1.940401 -0.648343 -1.986704 -0.346978   \n",
       "\n",
       "      f11_2     f18_2     f10_2     f16_2      f8_2     f13_2  \n",
       "0 -0.165420  0.877329  0.684882 -0.041809  2.285389 -0.688339  \n",
       "1  1.369378  1.721680 -1.527514 -0.234272  0.200160 -0.147486  \n",
       "2  3.237390  1.130163 -3.310383 -1.228359 -3.529958  0.776517  \n",
       "3  2.497054 -0.693162 -2.074722 -1.027206 -3.263632  0.990452  \n",
       "4 -0.000081 -1.558701 -0.040872 -0.748870 -0.606107  1.572000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_EHR2 = pd.read_csv(\"./data_EHR2.csv\")\n",
    "data_EHR2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c90fc5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 20)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_EHR2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e3dd20",
   "metadata": {},
   "source": [
    "# Get golden-standard-list from permutation matrix for the unmapped features in 2 EHRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d7781ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['f6_1', 'f7_1', 'f8_1', 'f9_1', 'f10_1', 'f11_1', 'f12_1', 'f13_1', 'f14_1', 'f15_1', 'f16_1', 'f17_1', 'f18_1', 'f19_1', 'f20_1']\n",
      "['f15_2', 'f14_2', 'f6_2', 'f17_2', 'f9_2', 'f7_2', 'f12_2', 'f20_2', 'f19_2', 'f11_2', 'f18_2', 'f10_2', 'f16_2', 'f8_2', 'f13_2']\n"
     ]
    }
   ],
   "source": [
    "# get permutation matrix for the unmapped features in 2 EHRs\n",
    "ump_f_EHR1 = list(data_EHR1.columns[5:])\n",
    "ump_f_EHR2 = list(data_EHR2.columns[5:])\n",
    "\n",
    "print(ump_f_EHR1)\n",
    "print(ump_f_EHR2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c5d03f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = np.zeros((len(ump_f_EHR1), len(ump_f_EHR2)))\n",
    "for i in range(len(ump_f_EHR1)):\n",
    "    for j in range(len(ump_f_EHR2)):\n",
    "        if ump_f_EHR1[i][1:-2] == ump_f_EHR2[j][1:-2]:\n",
    "            p[i][j] = 1\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f928975a",
   "metadata": {},
   "source": [
    "# Training seq-to-seq model to regard transformation function as the fingerprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f64b954c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer gen_data shape from (60000, 20) to (2500, 24, 20)\n",
    "data_1 = data_EHR1.to_numpy().reshape((2500, 24, 20))\n",
    "data_2 = data_EHR2.to_numpy().reshape((2500, 24, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a874be3",
   "metadata": {},
   "source": [
    "### Define Dataset\n",
    "* input: unmapped feature i in 2 EHRS (totally 15 unmapped features in 2 EHRs, the last 15 columns in data_1/data_2)\n",
    "* target: pre-mapped features in 2 EHRS (the first 5 columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "edf1182c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2seq_Dataset(Dataset):\n",
    "    def __init__(self, data, EHR_version): \n",
    "        self.patients_num = data.shape[0]\n",
    "        self.ump_features_list = []\n",
    "        self.mp_features_list = []\n",
    "        \n",
    "        # load mp_features\n",
    "        if os.path.exists(\"./mp_f_tensors_\" + str(EHR_version) + \".pt\"):\n",
    "            self.mp_features_list = torch.load(\"./mp_f_tensors_\" + str(EHR_version) + \".pt\")\n",
    "            print(\"Finish loading mapped features' tensors!\")\n",
    "        else:\n",
    "            for i in range(self.patients_num):\n",
    "                cur_mp_features = torch.tensor(data[i,:,:5])\n",
    "                self.mp_features_list.append(cur_mp_features.float())\n",
    "            \n",
    "            torch.save(self.mp_features_list, \"./mp_f_tensors_\" + str(EHR_version) + \".pt\")\n",
    "            print(\"Finish transforming mapped features' tensors!\")\n",
    "        \n",
    "        # load ump_features\n",
    "        if os.path.exists(\"./ump_f_tensors_\" + str(EHR_version) + \".pt\"):\n",
    "            self.ump_features_list = torch.load(\"./ump_f_tensors_\" + str(EHR_version) + \".pt\")\n",
    "            print(\"Finish loading unmapped features' tensors!\")\n",
    "        else:\n",
    "            for i in range(self.patients_num):\n",
    "                cur_ump_features = torch.tensor(data[i, :, 5:])\n",
    "                self.ump_features_list.append(cur_ump_features.float())\n",
    "                \n",
    "            torch.save(self.ump_features_list, \"./ump_f_tensors_\" + str(EHR_version) + \".pt\")\n",
    "            print(\"Finish transforming unmapped features' tensors!\")\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.patients_num\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample_mp_features = self.mp_features_list[idx]\n",
    "        # shape: [24, 5]\n",
    "        sample_ump_features = self.ump_features_list[idx]\n",
    "        # shape: [24, 15]\n",
    "        return sample_mp_features, sample_ump_features\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a59f08",
   "metadata": {},
   "source": [
    "# Define model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "daca774d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "import random\n",
    "# from torch.nn import BCEWithLogitsLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "53025671",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2seq_model(nn.Module):\n",
    "    def __init__(self, ump_feature_id, batch_size, input_dim, hidden_dim, seq_len, num_mp_f):\n",
    "        super(Seq2seq_model, self).__init__()\n",
    "        # each model trained on only one unmapped feature: ump_feature_id\n",
    "        # currently, ump_feature_id takes value from [0, 14]\n",
    "        self.ump_id = ump_feature_id\n",
    "        self.batch_size = batch_size\n",
    "        self.seq_len = seq_len\n",
    "        self.h_0 = torch.randn(1, self.batch_size, hidden_dim)\n",
    "        # RNN to get final hidden states\n",
    "        self.RNN = nn.RNN(input_dim, hidden_dim, batch_first=True, dropout=0.2)\n",
    "        # MLP to predict pre-mapped features(flatten to shape: seq_len x num_mp_f)\n",
    "        self.target_dim = seq_len * num_mp_f\n",
    "        self.dense1 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.MLP_drop1 = nn.Dropout(p=0.2)\n",
    "        self.dense2 = nn.Linear(hidden_dim, int(self.target_dim / 2))\n",
    "        self.MLP_drop2 = nn.Dropout(p=0.2)\n",
    "        self.dense3 = nn.Linear(int(self.target_dim / 2), self.target_dim)\n",
    "        self.MLP_drop3 = nn.Dropout(p=0.2)\n",
    "        self.dense4 = nn.Linear(self.target_dim, self.target_dim)\n",
    "        \n",
    "    def forward(self, input_data):\n",
    "        true_mapped_features = nn.Flatten()(input_data[0]) \n",
    "        # shape: [10, 24*5], targets\n",
    "        unmapped_features = input_data[1][:, :, self.ump_id].reshape((self.batch_size, self.seq_len, 1)) \n",
    "        # shape: [10, 24, 1], includes all unmapped features\n",
    "        output, h_n = self.RNN(unmapped_features, self.h_0)\n",
    "        # h_n: final hidden state with shape [1, batch_size, hidden_dim]\n",
    "        map_predict = self.dense1(h_n[0])\n",
    "        map_predict = nn.ReLU()(map_predict)\n",
    "        map_predict = self.MLP_drop1(map_predict)\n",
    "        \n",
    "        map_predict = self.dense2(map_predict)\n",
    "        map_predict = nn.ReLU()(map_predict)\n",
    "        map_predict = self.MLP_drop2(map_predict)\n",
    "        \n",
    "        map_predict = self.dense3(map_predict)\n",
    "        map_predict = nn.ReLU()(map_predict)\n",
    "        map_predict = self.MLP_drop3(map_predict)\n",
    "        \n",
    "        map_predict = self.dense4(map_predict) # shape [batch_size, seq_len * num_mp_f]\n",
    "        \n",
    "        criterion = nn.MSELoss()\n",
    "        loss = criterion(map_predict, true_mapped_features)\n",
    "        return {\"predicts\": map_predict, \"loss\": loss}\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3bc79b",
   "metadata": {},
   "source": [
    "# K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dae750",
   "metadata": {},
   "source": [
    "### a. Define train(), val() to call in each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "46be890d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, optimizer, batch_size):\n",
    "    size = len(train_loader.dataset)\n",
    "    model.train()\n",
    "    for i, data in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        cur_loss = model(data)[\"loss\"]\n",
    "        cur_loss.backward()\n",
    "        optimizer.step()\n",
    "#         if i % 100 == 0:\n",
    "#             loss, current = cur_loss.item(), i*len(data)\n",
    "#             print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
    "        \n",
    "            \n",
    "\n",
    "def val(val_loader, model, batch_size):\n",
    "    val_loss_sum = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(val_loader):\n",
    "            val_loss_sum += model(data)[\"loss\"]\n",
    "    avg_val_loss = val_loss_sum / len(val_loader)\n",
    "    return avg_val_loss\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a917e3da",
   "metadata": {},
   "source": [
    "### b. Split dataset into train+val (90%) & final_test (10%) parts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8e675df9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish transforming mapped features' tensors!\n",
      "Finish transforming unmapped features' tensors!\n",
      "Finish transforming mapped features' tensors!\n",
      "Finish transforming unmapped features' tensors!\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "\n",
    "dataset_1_all = Seq2seq_Dataset(data_1, 1)\n",
    "dataset_2_all = Seq2seq_Dataset(data_2, 2)\n",
    "\n",
    "dataset_1_kfold, dataset_1_final_test = random_split(dataset_1_all, [int(len(dataset_1_all) * 0.9), int(len(dataset_1_all) * 0.1)], generator=torch.Generator().manual_seed(42))\n",
    "dataset_2_kfold, dataset_2_final_test = random_split(dataset_2_all, [int(len(dataset_2_all) * 0.9), int(len(dataset_2_all) * 0.1)], generator=torch.Generator().manual_seed(42))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6eab74",
   "metadata": {},
   "source": [
    "### c. K-Fold cross validation to train and val model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a30112f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "from torch import optim\n",
    "\n",
    "num_epochs = 10\n",
    "batch_size = 10\n",
    "input_dim = 1 # each unmapped feature\n",
    "hidden_dim = 20 # hidden dim of RNN model\n",
    "num_ump_f = 15\n",
    "seq_len = 24\n",
    "num_mp_f = 5\n",
    "lr = 0.002\n",
    "k_folds = 5\n",
    "splits=KFold(n_splits=k_folds, shuffle=True,random_state=42)\n",
    "kfold_test_loss_1 = np.zeros((num_ump_f, k_folds))\n",
    "kfold_test_loss_2 = np.zeros((num_ump_f, k_folds))\n",
    "\n",
    "# trained on unmapped features in EHR1\n",
    "for fold, (train_idx, val_idx) in enumerate(splits.split(np.arange(len(dataset_1_kfold)))):\n",
    "    print('Fold {}'.format(fold + 1))\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    test_sampler = SubsetRandomSampler(val_idx)\n",
    "    train_loader = DataLoader(dataset_1_kfold, batch_size=batch_size, sampler=train_sampler)\n",
    "    test_loader = DataLoader(dataset_1_kfold, batch_size=batch_size, sampler=test_sampler)\n",
    "    for ump_f_id in range(num_ump_f):\n",
    "        model = Seq2seq_model(ump_f_id, batch_size, input_dim, hidden_dim, seq_len, num_mp_f)\n",
    "        optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "        cur_sum_loss = 0\n",
    "        for epoch in range(num_epochs):\n",
    "            train(train_loader, model, optimizer, batch_size)\n",
    "            cur_sum_loss += val(test_loader, model, batch_size)\n",
    "            \n",
    "        kfold_test_loss_1[ump_f_id, fold] = cur_sum_loss / num_epochs\n",
    "        \n",
    "# trained on unmapped features in EHR2\n",
    "for fold, (train_idx, val_idx) in enumerate(splits.split(np.arange(len(dataset_2_kfold)))):\n",
    "    print('Fold {}'.format(fold + 1))\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    test_sampler = SubsetRandomSampler(val_idx)\n",
    "    train_loader = DataLoader(dataset_2_kfold, batch_size=batch_size, sampler=train_sampler)\n",
    "    test_loader = DataLoader(dataset_2_kfold, batch_size=batch_size, sampler=test_sampler)\n",
    "    for ump_f_id in range(num_ump_f):\n",
    "        model = Seq2seq_model(ump_f_id, batch_size, input_dim, hidden_dim, seq_len, num_mp_f)\n",
    "        optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "        cur_sum_loss = 0\n",
    "        for epoch in range(num_epochs):\n",
    "            train(train_loader, model, optimizer, batch_size)\n",
    "            cur_sum_loss += val(test_loader, model, batch_size)\n",
    "            \n",
    "        kfold_test_loss_2[ump_f_id, fold] = cur_sum_loss / num_epochs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "261f620a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.18213463, 8.04709721, 8.00663662, 8.06370831, 8.20800972],\n",
       "       [7.66380835, 7.60657501, 7.65536594, 7.49697638, 7.75573874],\n",
       "       [8.00084209, 7.98895025, 7.9028368 , 7.89055109, 8.01455307],\n",
       "       [9.64537334, 9.24072456, 9.45179558, 9.28697777, 9.58749962],\n",
       "       [8.25765228, 8.00774956, 8.08473015, 7.97795248, 8.16930199],\n",
       "       [8.38163567, 8.17290974, 8.04883099, 7.86730051, 8.11237717],\n",
       "       [9.47379303, 9.24890041, 9.22126675, 9.24496269, 9.29763222],\n",
       "       [9.94843674, 9.64812946, 9.83619881, 9.62560272, 9.88210869],\n",
       "       [9.93941498, 9.62500858, 9.8076458 , 9.6150341 , 9.84286118],\n",
       "       [9.36569118, 9.07037258, 9.23637295, 8.99040127, 9.33036423],\n",
       "       [9.931633  , 9.62621975, 9.80823326, 9.6090517 , 9.84626579],\n",
       "       [9.8164959 , 9.56373024, 9.76970959, 9.50335884, 9.76703835],\n",
       "       [9.01693058, 8.68861008, 8.77471256, 8.67355728, 8.83125019],\n",
       "       [9.30682373, 9.12713432, 9.21259117, 9.01767159, 9.37334633],\n",
       "       [9.62224197, 9.30284023, 9.54317188, 9.27544403, 9.59063148]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold_test_loss_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "486d9ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.0212326 ,  9.18507957,  9.13533592,  9.18954945,  9.76801109],\n",
       "       [ 9.6192503 ,  9.88075733,  9.76010895,  9.67849541, 10.35847187],\n",
       "       [ 7.92218494,  8.06856155,  8.06936646,  7.91815281,  8.7112627 ],\n",
       "       [ 9.52457237,  9.75982857,  9.64916706,  9.63474655, 10.26062298],\n",
       "       [ 9.23663139,  9.48885059,  9.33452034,  9.35671711,  9.94048119],\n",
       "       [ 7.22630835,  7.42509317,  7.57019329,  7.65055466,  8.04555988],\n",
       "       [ 9.13063145,  9.34042358,  9.25703239,  9.15375996,  9.76223183],\n",
       "       [ 9.36997318,  9.58489799,  9.44891548,  9.46282005, 10.12315369],\n",
       "       [ 8.9656601 ,  9.25315762,  9.19209766,  9.10543823,  9.81880379],\n",
       "       [ 7.80669403,  8.04145527,  8.2769537 ,  8.08746624,  8.60482979],\n",
       "       [ 8.50068474,  8.86130333,  8.79769611,  8.63900948,  9.24771118],\n",
       "       [ 7.90849543,  8.09234524,  8.11461067,  8.15523624,  8.60020161],\n",
       "       [ 9.64540577,  9.90639877,  9.75844288,  9.69396019, 10.37814522],\n",
       "       [ 7.78965092,  7.90408421,  8.07209969,  7.88232899,  8.45515919],\n",
       "       [ 9.65868378,  9.90771866,  9.77860546,  9.70818806, 10.3949995 ]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold_test_loss_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38ca668",
   "metadata": {},
   "source": [
    "### d. Trained the final model using all the 90% training data (data used in the above 5-fold cross-validation process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6d67b33d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current unmapped feature id:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shutingcui/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current unmapped feature id:  1\n",
      "current unmapped feature id:  2\n",
      "current unmapped feature id:  3\n",
      "current unmapped feature id:  4\n",
      "current unmapped feature id:  5\n",
      "current unmapped feature id:  6\n",
      "current unmapped feature id:  7\n",
      "current unmapped feature id:  8\n",
      "current unmapped feature id:  9\n",
      "current unmapped feature id:  10\n",
      "current unmapped feature id:  11\n",
      "current unmapped feature id:  12\n",
      "current unmapped feature id:  13\n",
      "current unmapped feature id:  14\n"
     ]
    }
   ],
   "source": [
    "final_train_dataloader_1 = DataLoader(dataset_1_kfold, batch_size=batch_size, shuffle=True)\n",
    "for umpf_id in range(num_ump_f):\n",
    "    print(\"current unmapped feature id: \", umpf_id)\n",
    "    cur_model = Seq2seq_model(umpf_id, batch_size, 1, hidden_dim, seq_len, num_mp_f)\n",
    "    cur_optimizer = optim.Adam(cur_model.parameters(), lr = lr)\n",
    "    for i in range(num_epochs):\n",
    "#         print(f\"Epoch {i+1}\\n-------------------------------\")\n",
    "        train(final_train_dataloader_1, cur_model, cur_optimizer, batch_size)\n",
    "    \n",
    "    torch.save(cur_model.state_dict(), \"./each_umpf_model_param/EHR1/umpf_\"+str(umpf_id+1)+\"_EHR1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "027fd3a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current unmapped feature id:  0\n",
      "current unmapped feature id:  1\n",
      "current unmapped feature id:  2\n",
      "current unmapped feature id:  3\n",
      "current unmapped feature id:  4\n",
      "current unmapped feature id:  5\n",
      "current unmapped feature id:  6\n",
      "current unmapped feature id:  7\n",
      "current unmapped feature id:  8\n",
      "current unmapped feature id:  9\n",
      "current unmapped feature id:  10\n",
      "current unmapped feature id:  11\n",
      "current unmapped feature id:  12\n",
      "current unmapped feature id:  13\n",
      "current unmapped feature id:  14\n"
     ]
    }
   ],
   "source": [
    "final_train_dataloader_2 = DataLoader(dataset_2_kfold, batch_size=batch_size, shuffle=True)\n",
    "for umpf_id in range(num_ump_f):\n",
    "    print(\"current unmapped feature id: \", umpf_id)\n",
    "    cur_model = Seq2seq_model(umpf_id, batch_size, 1, hidden_dim, seq_len, num_mp_f)\n",
    "    cur_optimizer = optim.Adam(cur_model.parameters(), lr = lr)\n",
    "    for i in range(num_epochs):\n",
    "#         print(f\"Epoch {i+1}\\n-------------------------------\")\n",
    "        train(final_train_dataloader_2, cur_model, cur_optimizer, batch_size)\n",
    "    \n",
    "    torch.save(cur_model.state_dict(), \"./each_umpf_model_param/EHR2/umpf_\"+str(umpf_id+1)+\"_EHR2.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f38c250",
   "metadata": {},
   "source": [
    "### e. Test the final trained model's performance on 2 EHRs  \n",
    "* using dataset:  dataset_1_final_test & dataset_2_final_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5e5ade2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list_ump_EHR1 = []\n",
    "models_list_ump_EHR2 = []\n",
    "for i in range(1, 16):\n",
    "    cur_model_1_pth = \"./each_umpf_model_param/EHR1/umpf_\" + str(i) + \"_EHR1.pth\"\n",
    "    cur_model_2_pth = \"./each_umpf_model_param/EHR2/umpf_\" + str(i) + \"_EHR2.pth\"\n",
    "    \n",
    "    cur_model_1 = Seq2seq_model(i-1, batch_size, input_dim, hidden_dim, seq_len, num_mp_f)\n",
    "    cur_model_1.load_state_dict(torch.load(cur_model_1_pth))\n",
    "    \n",
    "    cur_model_2 = Seq2seq_model(i-1, batch_size, input_dim, hidden_dim, seq_len, num_mp_f)\n",
    "    cur_model_2.load_state_dict(torch.load(cur_model_2_pth))\n",
    "    \n",
    "    models_list_ump_EHR1.append(cur_model_1)\n",
    "    models_list_ump_EHR2.append(cur_model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3d18f19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_1_test = DataLoader(dataset_1_final_test, batch_size=10)\n",
    "dataloader_2_test = DataLoader(dataset_2_final_test, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3fd3fecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_dl_1 = len(dataloader_1_test)\n",
    "len_dl_2 = len(dataloader_2_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "43d77518",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.74261856e-02  2.39768243e-02  3.25501652e-02  2.52910724e-02\n",
      "  -2.06761370e-03  3.72644125e-02 -4.39876936e-03  2.06935651e-02\n",
      "   8.66800412e-03  3.09546529e-02 -3.91203036e-02  3.71582729e-02\n",
      "   2.58954518e-02  4.81017568e-02  1.02139264e-05]\n",
      " [ 1.74765666e-02  8.55164400e-03 -1.47844531e-02  2.74632012e-02\n",
      "   3.33786751e-02 -1.14453827e-02 -4.23046756e-02  1.85523012e-02\n",
      "   4.34630819e-03  5.42731808e-03 -5.91968254e-02 -1.01243979e-02\n",
      "  -4.48608652e-02  3.05853141e-04 -6.34039233e-02]\n",
      " [ 2.28576269e-02  2.04307055e-02 -4.77591167e-03  4.57326017e-02\n",
      "   9.86208860e-04  1.97132845e-02 -3.95645911e-02  5.90214178e-02\n",
      "   3.39519310e-02  1.30725086e-02 -5.42575976e-02 -3.04407598e-02\n",
      "   5.14139559e-02  2.44664263e-03  2.06064633e-02]\n",
      " [-2.36018157e-02  3.59492260e-02 -7.70573418e-03  4.44698165e-02\n",
      "  -2.46900562e-02  1.25560965e-03  4.01685046e-02  3.04423901e-02\n",
      "  -4.66275722e-03  4.87156400e-03 -7.50882515e-02 -6.25320591e-03\n",
      "   4.26782624e-02  2.15550785e-02 -3.55003559e-02]\n",
      " [-4.10919409e-02  4.43218483e-02  2.57510474e-02  3.13651199e-02\n",
      "  -4.73176270e-02  2.57361501e-02 -1.53952452e-03  1.24816601e-02\n",
      "   2.55973435e-02  7.73867199e-03 -2.51869013e-02 -3.65369976e-02\n",
      "   1.78364358e-02  2.79173516e-02  2.56871816e-02]\n",
      " [ 1.35514825e-02  4.66467116e-02  7.97678575e-03  3.15081229e-02\n",
      "   1.42261295e-02  3.23558951e-02  2.31828587e-03  3.18085325e-02\n",
      "   3.11632226e-02  5.79266690e-03 -4.38551784e-02 -1.40697925e-02\n",
      "   3.69478653e-02  3.70248883e-02  1.95977421e-02]\n",
      " [-1.41437319e-02  4.08220871e-03 -2.17167879e-02 -9.48298026e-03\n",
      "   8.55815801e-03 -1.18610998e-02 -3.62268083e-02 -8.50996594e-03\n",
      "   7.15228833e-03 -2.72715713e-02 -5.43859158e-02 -3.35986624e-02\n",
      "  -1.71518433e-02 -5.55020974e-03  1.22198794e-02]\n",
      " [-1.38301311e-01 -1.11348998e-01  4.92899300e-02 -6.47748473e-02\n",
      "  -1.42983211e-02 -4.49499649e-02 -5.50104779e-02 -3.26736162e-02\n",
      "  -3.28629894e-03 -1.01119168e-02  4.33508185e-02  4.61088425e-02\n",
      "  -3.03852179e-01  3.02428009e-03 -2.62218607e-01]\n",
      " [-4.42148236e-02  8.66920125e-03  7.66396489e-03 -2.57873194e-03\n",
      "   1.82722344e-03 -2.54209945e-02 -1.03040269e-02  1.20312258e-02\n",
      "   1.83477458e-02  4.26253507e-03  3.50945103e-02 -3.69475026e-03\n",
      "  -6.94567209e-02  1.84588265e-04 -8.66949585e-02]\n",
      " [ 3.90557720e-02  3.36409189e-02  2.63111922e-02  8.03995921e-02\n",
      "   4.89063089e-02  5.95487390e-02  3.93258812e-02  4.29850415e-02\n",
      "   1.19581819e-06  4.73788417e-02  1.21965828e-02  2.32069405e-02\n",
      "  -6.98174313e-03  4.48913084e-02 -7.43109301e-03]\n",
      " [-3.51777850e-02 -2.01571937e-02  1.36266813e-02 -2.13633124e-02\n",
      "  -4.08593066e-02 -3.79260543e-03  3.50721428e-03 -1.20853704e-02\n",
      "   3.85671959e-03  2.00790728e-02  3.18064383e-02  1.99795965e-03\n",
      "  -2.22450545e-02  9.07347811e-03 -2.15907546e-02]\n",
      " [-2.82344777e-02  5.02284829e-03 -2.21490950e-02  8.54645648e-03\n",
      "   2.25700993e-02 -5.96230783e-03 -2.53618555e-03 -5.20682906e-02\n",
      "  -1.56943127e-02  3.03448409e-03 -5.63076156e-03 -2.74894998e-02\n",
      "  -1.33485101e-02 -1.84907118e-02 -2.89425710e-02]\n",
      " [ 1.38884713e-02 -1.91066819e-03 -1.36315927e-02  1.32101163e-02\n",
      "   2.94891891e-02  1.25530496e-03 -1.71901837e-02  1.14088004e-02\n",
      "  -1.90463181e-02 -3.32669924e-03 -4.70251049e-02 -1.19626254e-02\n",
      "  -1.08418608e-03 -5.05794007e-04 -5.54029591e-02]\n",
      " [-3.36146898e-02  2.71505155e-03 -8.08858791e-03 -9.02535072e-03\n",
      "  -2.82235311e-02 -1.68078370e-02  1.45096185e-03  3.32496608e-02\n",
      "   1.11418258e-02 -1.77224936e-02 -2.73303466e-02 -3.02924602e-02\n",
      "   7.25196097e-03 -1.96868169e-02  3.64886355e-02]\n",
      " [-1.03249379e-01  3.20127755e-02  3.40094347e-02 -5.43596345e-02\n",
      "  -3.51411524e-02  1.54220974e-02  5.96283965e-03 -3.30390875e-02\n",
      "   1.56714651e-02  8.32415693e-03  3.56358977e-02 -1.01844906e-02\n",
      "  -6.50101994e-02  1.19932126e-02 -3.84134159e-02]]\n"
     ]
    }
   ],
   "source": [
    "num_ump_f_1 = 15\n",
    "num_ump_f_2 = 15\n",
    "avg_cos_sim_matrix = np.zeros((num_ump_f_1, num_ump_f_2))\n",
    "for ump_i_1 in range(15):\n",
    "    cur_model_1 = models_list_ump_EHR1[ump_i_1]\n",
    "    cur_model_1.eval()\n",
    "    cur_umpf_1_to_all_umpf_2 = np.zeros((len_dl_1, num_ump_f_2))\n",
    "    for index, (data1, data2) in enumerate(zip(dataloader_1_test, dataloader_2_test)):\n",
    "        pred_map_1 = cur_model_1(data1)[\"predicts\"] \n",
    "        pred_map_1_asarray = pred_map_1.detach().numpy() # (10, 120)\n",
    "        for ump_i_2 in range(15):\n",
    "            cur_model_2 = models_list_ump_EHR2[ump_i_2]\n",
    "            cur_model_2.eval()\n",
    "            pred_map_2 = cur_model_2(data2)[\"predicts\"]\n",
    "            pred_map_2_asarray = pred_map_2.detach().numpy() # (10, 120)\n",
    "            cur_cosine_sim = np.sum(pred_map_1_asarray*pred_map_2_asarray, axis=1) / (norm(pred_map_1_asarray, axis=1)*norm(pred_map_2_asarray, axis=1))\n",
    "            cur_umpf_1_to_all_umpf_2[index][ump_i_2] = np.average(cur_cosine_sim)\n",
    "    avg_cos_sim_matrix[ump_i_1, :] = np.average(cur_umpf_1_to_all_umpf_2, axis=0)\n",
    "\n",
    "    \n",
    "print(avg_cos_sim_matrix)\n",
    " \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d444d81",
   "metadata": {},
   "source": [
    "# The predicted matched features for each unmapped feature in EHR1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4b59b985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13,  4,  7,  3,  1,  1, 14,  2, 10,  3, 10,  4,  4, 14, 10])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_matched_for_umf1 = avg_cos_sim_matrix.argmax(axis = 1)\n",
    "pred_matched_for_umf1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dea4db",
   "metadata": {},
   "source": [
    "# The actual matched feature for each unmapped feature in EHR1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e6a6500a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  5, 13,  4, 11,  9,  6, 14,  1,  0, 12,  3, 10,  8,  7])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_matched_for_umf1 = p.argmax(axis=1)\n",
    "actual_matched_for_umf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cf8a17ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_perf = (pred_matched_for_umf1 == actual_matched_for_umf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ae8eb91d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194680dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
